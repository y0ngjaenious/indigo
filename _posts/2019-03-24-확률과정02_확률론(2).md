---
layout: post
title: 확률과정02-확률론(2)
date: 2019-03-24 12:48
use_math: true
comments: true
headerImage: false
categories: Machine Learning/Stochastic Process
tags:
- StochasticProcess
- Statistics
author: y0ngjae
description: Axiomatic definition of probability
---

***Author : Jiwoo Lim***

## 연속확률변수와 연속확률분포

1. 웨이블 분포

   - $\Large{f(x) = \frac{\alpha}{\beta^\alpha}x^{\alpha-1}e^{-(\frac{x}{\beta})^\alpha}} $, $x\ge0$

   - 지수분포를 보다 일반화시켜 , 다양한 확률분포 형태를 나타낼 수 있도록 고안됨

   - 부품 고장까지의 시간 혹은 수명 등과 같이 신뢰성과 수명시험 문제에서 주로 사용

   - 생존분석에서 생존시간에 대해 지수분포를 사용하는 것은 위험율(hazard rate)이 시간에 상관없이 constant하다고 가정하는 것인데,

     웨이블분포를 사용하면 시간에 따라 constant하지 않고 변하는 경우도 modeling 가능

2. 위험률 함수

   - 확률변수 X: 어떤 수명을 나타내는 함수,  F : 분포함수,  f : 확률밀도함수라 하자
   - 분포함수 F에 대한 위험률함수  $\large{\lambda(t) = \frac{f(t)}{1-F(t)}}=\frac{d}{dt}(-log(1-F(t))$
     - $\large{P(t<X\le{t+\Delta{t}}IX>t) = \frac{P(t<X\le{t+\Delta{t}})}{P(X>t)} \approx\frac{f(t)\Delta{t}}{1-F(t)}=\lambda(t)\Delta{t}}$ : ($\Delta{t}\to0: $순간 위험률)
     - $\lambda(t)​$: 수명이 t 이상일 때 t 시점을 지나면서 사망하는 조건부 확률강도(  고장률 함수는 복구 (또는 초기화) 시간을 0이라고 했을 때 임의의 시간 t에서 고장이 발생할 확률 )
   - 분포함수/확률밀도함수 $\rightleftharpoons​$ $\lambda(t)​$

----

## 다차원확률변수와 결합확률분포

1. 조건부 분포

   ​      <이산확률변수>

   -  <u>Y=y일 때 X의 조건부확률질량함수</u> $p_{XIY}(xIy)​$는 다음과 같이 정의된다.
      -  $\large{p_{XIY}(xIy)=\frac{p(x,y)}{p_Y(y)}},  (p_Y(y)\ne0) ​$
   -  <u>Y=y일 때 X의 조건부확률분포함수</u> $F_{XIY}(xIy)​$는 다음과 같이 정의된다
      -  $\large{F_{XIY}(aIy)=P(X\le{a}IY=y)=\sum_{\{xIx\le{a}\}}p_{XIY}(xIy)}​$

   ​      

   ​     <연속확률변수>

   -  <u>Y=y일 때 X의 조건부확률밀도함수</u> $f_{XIY}(xIy)$는 다음과 같이 정의된다.
      - $\large{f_{XIY}(xIy)=\frac{f(x,y)}{f_Y(y)}},  (f_Y(y)\ne0) ​$
   -  <u>Y=y일 때 X의 조건부확률분포함수</u> $F_{XIY}(xIy)​$는 다음과 같이 정의된다
      -  $\large{F_{XIY}(xIy)=P(X\le{x}IY=y)=\int_{-\infty}^xf_{XIY}(xIy)dx}$



2. 순서통계량

   - $(x_1,x_2,x_3)$을 순서대로 정렬하는 상황을 고려해보자. $y_1=min(x_1,x_2,x_3),y_2=\text{두번째로 작은 값},y_3=max(x_1,x_2,x_3)$이라 하자. 

     $(y_1,y_2,y_3)=(1,2,3)​$이라 하면, 대응되는 $(x_1,x_2,x_3)​$은 6가지 경우가 가능하다. 일반적으로 순서대로 정렬한 결과가 $(y_1,y_2,...,y_n)​$이 되는 $(x_1,x_2,...,x_n)​$의 가능한 가지 수는 $y_i​$가 서로 다르다고 가정할 경우 n! 가지이다. 따라서 $(x_1,x_2,...,x_n)\to(y_1,y_2,...,y_n)​$ 변환은 n! : 1의 변환이 된다.

   - $X_1,X_2,...,X_n$은 iid이고, $X_i$의 확률밀도함수는 $f(x)$라 하자. $Y_1=min(X_1,X_2,...,X_n), Y_2=X_1,X_2,...,X_n$ 중에서 두 번째로 작은 값,...,$Y_n=max(X_1,X_2,...,X_n)$의 변환을 고려해보자.

     - $f_Y(y_1,y_2,...,y_n)=f_{X}(x_1=y_1,x_2=y_2,...,x_n=y_n)IJI+f_{X}(x_1=y_2,x_2=y_1,...,x_n=y_n)IJI+...+f_{X}(x_1=y_n,x_2=y_{n-1},...,x_n=y_1)IJI=n!f_X(y_1)f_X(y_2)...f_X(y_n),  (y_1<y_2<...<y_n)$
     - $f_{Y_1,Y_2,...,Y_n}(y_1,y_2,...,y_n)=n!f_X(y_1)f_X(y_2)...f_X(y_n), (y_1<y_2,...<y_n)$

   - 일반적으로 $Y_1=X_{(1)}, Y_2=X_{(2)},...,Y_n=X_{(n)}​$으로 나타내며, $X_{(1)}\le{X_{(2)}}\le{...}\le{X_{(n)}}​$을 $X_1,X_2,...,X_n​$의 <u>**순서통계량**</u>이라 한다.

     

   - $X_{(i)}​$의 확률밀도함수 구하는 방법

     - $x\le{X_{(i)}}\le{x+\Delta{x}}$는 $X_1,X_2,...,X_n$ 중에서 i-1개는 x보다 작고 하나는 $(x,x+\Delta{x})$ 사이에 있으며 나머지 n-i개는 $x+\Delta{x}$보다 크다고 할 수 있다. 

       따라서 $P(x<X_{(i)}\le{x+\Delta{x}})=$${n}\choose{i-1}$$(P(X\le{x}))^{i-1}$${n-i+1}\choose{1}$$P(x<X\le{x+\Delta{x}})(P(X>x+\Delta{x}))^{n-i}$

       => $f_{X(i)}(x)=n$${n-1}\choose{i-1}$$(F(x))^{i-1}(1-F(x))^{n-i}f(x)$

   - $X_{(i)}와 X_{(j)}, i<j​$의 결합분포 구하는 방법

     -  $x\le{X_{(i)}}\le{x+\Delta{x}},  $ $y\le{X_{(j)}}\le{y+\Delta{y}}$는 $X_1,X_2,...,X_n$ 중에서 i-1개는 x보다 작고, 하나는 $(x,x+\Delta{x})$ 사이에 있으며,  j-i-i개는$(x+\Delta{x},y)$ 사이에 있고, 하나가 $(y,y+\Delta{y})$, 나머지 n-j개가 $y+\Delta{y}​$보다 크다고 할 수 있다. 

       =>$f_{X_{(i)},X_{(j)}}(x,y)=\frac{n!}{(i-1)!(j-i-1)!(n-j)!}(F(x))^{i-1}(F(y)-F(x))^{j-i-1}$ x $(1-F(y))^{n-j}f(x)f(y)$

   - 확률변수 $X_1,X_2,...,X_n$이 독립이더라도 이 확률변수들의 순서통계량은 종속임! 

   - 언제 쓰이는가?



3. 여러가지 유용한 부등식

   - 마르코프 부등식

     - $X\ge{0}$이면 임의의 $a>0$에 대해 
       - $P(X\ge{a})\le{\frac{E(X)}{a}}​$
   - 체비셰프 부등식

     - $X​$가 유한한 평균과 분산을 가진다면, 마르코프 부등식의 $X​$ 대신에 $IX-E(X)I\ge{0}​$  대입

       - $P(IX-E(X)I\ge{a})=P(IX-E(X)I^2\ge{a^2})\le{\frac{Var(X)}{a^2}}​$

         <=>   $P(IX-E(X)I<{a})\ge{1-\frac{Var(X)}{a^2}}$

       - $a=k\sigma, E(X)=\mu,Var(X)=\sigma^2​$으로 놓는다면

         - $P(-k\sigma<X-\mu<k\sigma)=P(\mu-k\sigma<X<\mu+k\sigma)\ge{1-\frac{1}{k^2}}​$

           => 확률변수의 *pdf/pmf*를 모르더라도 최소 몇퍼센트의 확률로 특정범위에 속할지 구할 수 있음

       - 일반적으로 체비셰프 부등식은 평균뿐 아니라 분산도 이용하여 마르코프 부등식보다 더 실제 값에 가까운 상한을 제시

   - 젠슨의 부등식
     - 함수 f가 볼록함수(convex)이고 $E(X)<\infty, E(f(X))<\infty$이면
       - $E(f(X))\ge{f(E(X))}​$
         - $\mu^2<E(X^2)$



4. 조건부 기댓값, 조건부 분산

   - 조건부 기댓값

     - $E(XIY=y)=\sum_{x}xp_{XIY}(xIy)=\int_{-\infty}^{\infty}xf_{XIY}(xIy)dx​$

     - $E(g(X)IY=y)=\sum_{x}g(x)p_{XIY}(xIy)=\int_{-\infty}^{\infty}g(x)f_{XIY}(xIy)dx​$

     - 조건부 기댓값은 기댓값을 구하기 위하여 사용되는 분포가 X의 분포=>Y=y일 때의 X의 조건부 분포로 바뀔 뿐, 기댓값의 성질들은 그대로 성립!

     - $E(XIY=y)$는 y의 함수이고, $E(YIX=x)$는 x의 함수

     - $\bold{E(X)=E(E(XIY))}​$

       - $E(XIY=y)=h(y)$라 두면 $E(XIY)=h(Y)$로 표현 가능하고, 이는 $E(XIY)$가 $Y​$의 함수임을 보여준다. 

         따라서 $Y​$의 분포를 이용하여 $h(Y)​$의 기댓값 $E(E(XIY))=E(h(Y))​$를 구할 수 있고, 이는 $E(X)​$와 같다.

       - $E(E(XIY))=\int_{-\infty}^{\infty}E(XIY=y)f_Y(y)dy$ = $\int_{-\infty}^{\infty}(\int_{-\infty}^{\infty}xf_{XIY}(xIy)dx)f_Y(y)dy$ = $\int_{-\infty}^{\infty}\int_{-\infty}^{\infty}xf(x,y)dxdy$ = $E(X)$

       - $E[XIY]=E[E[XIY,Z]IY]$

     - $E(g(X,Y))=\sum_{y}E(g(X,Y)I{Y=y})p_{Y}(y)=\int_{-\infty}^{\infty}E(g(X,Y)IY=y)f_{Y}(y)dy$

   - 조건부 분산

     - $Var(XIY)=E[(X-E(XIY))^2IY]=E(X^2IY)-E(XIY)^2​$
     - $E(Var(XIY))=E[E(X^2IY)]-E[E(XIY)^2]​$ = $E(X^2)-E[E(XIY)^2]​$
     - $Var(E(XIY))=E[E(XIY)^2]-E(X)^2$
     - $\bold{Var(X)=E[Var(XIY)]+Var(E(XIY))}$



-----

## 생성함수와 극한정리

1. 확률생성함수

   - $Q(r)=(pr+(1-p))^n=\sum_{i=0}^n$${n}\choose{i}$$(pr)^i(1-p)^{n-i}=\sum_{i=0}^np(i)r^i=E(r^X)$ 이라 정의해보자.

     여기서 모든 i에 대해 $p(i)​$를 알면 $Q(r)​$이 결정되고 반대도 마찬가지이다. 즉, 분포와 $Q(r)​$이 서로 대응된다.

   - 확률변수 X가 음이 아닌 정숫값을 갖는 확률변수일 때 X의 확률생성함수 $Q_X(r)$은 다음과 같이 정의된다.

     - $Q_X(r)=E(r^X)​$

       - $Q_X(r)$은 최소한 $IrI\le{1}$을 만족하는 r에 대해서 존재

       - $Q_X(r)=\sum_{i=0}^{\infty}p(i)r^i=p(0)+p(1)r+p(2)r^2+...$

         => $\frac{d^n}{dr^n}Q_X(r)I_{r=0}=n!p(n)$

     - $Q_X^{(n)}(1^-)=E[X(X-1)...(X-n+1)]​$ : 특히 우변을 X의 n차 factorial moment라 함

     - $Q_X(r)=Q_Y(r)\Leftrightarrow p_X(i)=p_Y(i)​$: 확률생성함수가 같으면 분포가 같다



2. 적률생성함수
   - 확률생성함수는 확률변수가 음이 아닌 정숫값을 가질 때 정의되는데, 적률생성함수는 보다 넓은 범위의 확률변수에 적용 가능하다.
   - 확률변수 X의 mgf
     - $M_X(t)=E(e^{tX}), ( ItI<d, d>0)​$: 해당 범위를 만족하는 모든 t에 대하여 기댓값 $E(e^{tX})​$
     - $E(X^m)​$: 확률변수 X의 m번째 moment
     - mgf는 X가 아닌 t에 대한 함수임
   - $Y=aX+b$일 때 Y의 mgf
     - $M_Y(t)=M_{aX+b}(t)=e^{bt}M_X(at)$
   - X의 mgf인 $M_X(t)​$를 n차 미분한 다음 t=0을 대입하면 X의 n차 momet를 구할 수 있다
     - $M_X^{(n)}(t)I_{t=0}=M^{(n)}(0)=E(X^n)$
     - $\large{M'(t)=\frac{dM(t)}{dt}=\frac{d}{dt}\int_{-\infty}^{\infty}e^{tx}f_X(x)dx=\int_{-\infty}^{\infty}\frac{d}{dt}e^{tx}f_X(x)dx=\int_{-\infty}^{\infty}xe^{tx}f_X(x)dx=\sum_xxe^{tx}p_X(x)}$
   - $M_X(t)=M_Y(t), ( ItI<d, d>0)\Leftrightarrow​$두 확률변수 X와 Y의 분포가 일치(유일성의 정리)
   - 결합적률생성함수
     - $M_{X_1,X_2,...,X_n}(t_1,t_2,...,t_n)=M(t_1,t_2,...,t_n)=E[exp(\sum_{i=1}^nt_iX_i)]=E[e^{t_1X_1+t_2X_2+...+t_nX_n}]$
       - $M(0,...,0,t_j,0,...,0)=M_{X_j}(t_j)​$
       - $(X_1,X_2,...,X_n)​$의 결합분포와 $(X_1,X_2,...,X_n)​$의 mgf인 $M(t_1,t_2,...,t_n)​$은 일대일 대응관계 존재(유일성의 정리)
       - $X_1,X_2,...,X_n​$이 서로 독립 $\Leftrightarrow M(t_1,t_2,...,t_n)=M_{X_1}(t_1)M_{X_2}(t_2)...M_{X_n}(t_n)​$: 확률변수가 독립이면 $E(XY)=E(X)E(Y)​$이므로

3. 라플라스변환
   - 음이 아닌 확률변수를 주로 다루는 분야에서 mgf 대신 라플라스변환을 주로 이용
   - $L(\theta)=E(e^{-\theta{X}})=\int_0^{\infty}e^{-\theta{x}}f(x)dx$,   $\theta\ge0$
   - $\theta​$는 복소수의 값을 가짐



4. 중심극한정리

   - $X_1,X_2,X_3,...$는 iid이고, $\mu=E(X_1)<\infty,\sigma^2=Var(X_1)<\infty$라 하면 $n\to\infty$일 때 다음이 성립한다
     - $\large{T_n=\frac{\sum_{i=1}^nX_i-n\mu}{\sigma\sqrt{n}}=\frac{\bar{X}-\mu}{\frac{\sigma}{\sqrt{n}}}\to{Z}\sim{N(0,1)}}$

   - 동일한 확률분포를 가지는 확률변수 n개의 평균의 분포는 n이 충분히 크다면 "정규분포"에 가까워짐
   - 알 수 없는 모집단에서 표본이 충분히 크다면, 이 표본평균의 분포는 정규분포에 근사한다
